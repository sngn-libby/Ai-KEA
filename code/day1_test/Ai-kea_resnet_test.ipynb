{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ai-kea_resnet_test.ipynb","provenance":[],"collapsed_sections":["i5KBK1OfW1-e"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RJQ3rrtzJj-6","colab_type":"text"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"FIZRq996GNGQ","colab_type":"code","outputId":"00a19aa2-51e5-4f0c-84c6-40e37ea75fda","executionInfo":{"status":"ok","timestamp":1576490641653,"user_tz":-540,"elapsed":4487,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["%tensorflow_version 2.x\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pathlib\n","\n","from __future__ import print_function\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Dense, Flatten,  Conv2D, BatchNormalization, Activation, Dropout\n","from tensorflow.keras.layers import AveragePooling2D, Input\n","from tensorflow.keras.layers import MaxPool2D, MaxPool1D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.regularizers import l2\n","#from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import os\n","\n","from google.colab import drive\n","\n","print(\"Module Loaded.\")\n","print(\"TensorFlow Version :{}\".format(tf.__version__))\n","print(\"NumPy Version :{}\".format(np.__version__))\n","print(\"Matplotlib Version :{}\".format(plt.matplotlib.__version__))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n","Module Loaded.\n","TensorFlow Version :2.0.0\n","NumPy Version :1.17.4\n","Matplotlib Version :3.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qhGeRQHgH5nv","colab_type":"code","outputId":"40353573-58c0-4ee7-9215-aa1ebddcc402","executionInfo":{"status":"ok","timestamp":1576490641654,"user_tz":-540,"elapsed":4476,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["drive.mount('/content/drive')\n","\n","data_path = pathlib.Path('/content/drive/Shared drives/scsa_2019_b/Project_Ai-KEA/data/furniture')\n","\n","num = 0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WFMO5e5FJf--","colab_type":"code","outputId":"a8bf8e96-456a-4a19-bfb8-b7fed8671a83","executionInfo":{"status":"ok","timestamp":1576490641654,"user_tz":-540,"elapsed":4465,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["class_name = np.array([item.name for item in data_path.glob('*')])\n","print(class_name)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['rug' 'curtain' 'table' 'bed' 'bookshelves' 'sofa' 'makeup_table' 'chair'\n"," 'standing_lamp' 'entertainment_center']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aIgZscP38sgg","colab_type":"text"},"source":["# Prepare Data"]},{"cell_type":"markdown","metadata":{"id":"BpHewyEx9AF8","colab_type":"text"},"source":["- **Unzip Data**"]},{"cell_type":"code","metadata":{"id":"J3n_9tqG8zTd","colab_type":"code","outputId":"b86bd42c-c888-426c-c3eb-9e7af47bcc04","executionInfo":{"status":"ok","timestamp":1576490641655,"user_tz":-540,"elapsed":4456,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os\n","\n","cwd = os.getcwd()\n","print(cwd)\n","\n","# !unzip /content/drive/Shared\\ drives/scsa_2019_b/Project_Ai-KEA/data_resize/furniture.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kdywAXtBGVM5","colab_type":"code","colab":{}},"source":["# Training parameters\n","\n","num_classes = 10\n","\n","# Subtracting pixel mean improves accuracy\n","subtract_pixel_mean = True\n","\n","# Model parameter\n","\n","# ResNet14   n=2\n","# ResNet20   n=3 \n","# ResNet32   n=5     \n","n = 1 #3\n","\n","# Model version\n","version = 1\n","\n","# Computed depth from supplied model parameter n\n","depth = n * 6 + 2\n","\n","# Model name, depth and version\n","model_name = 'ResNet%dv%d' % (depth, version)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i5KBK1OfW1-e","colab_type":"text"},"source":["# Resize Image"]},{"cell_type":"code","metadata":{"id":"rC5MO5l7W4UV","colab_type":"code","colab":{}},"source":["# from PIL import Image\n","\n","# for j in class_name[1:4]:\n","#     image = pathlib.Path('/content/drive/Shared drives/scsa_2019_b/Project_Ai-KEA/data/furniture/'+j)\n","#     image = list(image.glob('*.jpg'))\n","#     for i in range(len(image)):\n","#         im = Image.open(str(image[i])).convert('RGB')\n","#         resize_image = im.resize((im.size[0]//2,im.size[1]//2))\n","#         resize_image.save('/content/drive/Shared drives/scsa_2019_b/Project_Ai-KEA/data_resize/furniture/{0}/{1}{2:03d}.jpg'.format(j,j,i))\n","#         print(j, i)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JH2DuYx23-J","colab_type":"code","colab":{}},"source":["data_path = pathlib.Path('/content/drive/Shared drives/scsa_2019_b/Project_Ai-KEA/data_resize/furniture')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FbtVLWgALzkH","colab_type":"text"},"source":["#ImageGenerator"]},{"cell_type":"code","metadata":{"id":"LfzH4PjLPRME","colab_type":"code","colab":{}},"source":["img_size = 224\n","batch_n = 200\n","\n","data_path = pathlib.Path('/content/furniture')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwYTRqdTLLJm","colab_type":"code","colab":{}},"source":["image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","                                #width_shift_range=0.3,\n","                                #height_shift_range=0.3,\n","                                #horizontal_flip=True, \n","                                #vertical_flip=True,\n","                                #rotation_range=30,\n","                                #zoom_range=0.1,\n","                                #brightness_range=[0.8,1.2],\n","                                validation_split=0.2,\n","                                rescale=1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhkIbZYgNVkg","colab_type":"code","outputId":"de2e8650-7653-4ef3-8784-2380922ae976","executionInfo":{"status":"ok","timestamp":1576490641658,"user_tz":-540,"elapsed":4416,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["train_data_generate = image_generator.flow_from_directory(\n","                        directory=str(data_path),\n","                        batch_size=batch_n,\n","                        shuffle=True,\n","                        target_size=(img_size, img_size),\n","                        classes = list(class_name),\n","                        subset='training')\n","test_data_generate = image_generator.flow_from_directory(\n","                        directory=str(data_path),\n","                        batch_size=batch_n,\n","                        shuffle=True,\n","                        target_size=(img_size, img_size),\n","                        classes = list(class_name),\n","                        subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Found 3705 images belonging to 10 classes.\n","Found 921 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BF3VW7SWGqxd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"ba6fb111-a8d1-4f96-def6-5ccdff2ae38e","executionInfo":{"status":"error","timestamp":1576490646886,"user_tz":-540,"elapsed":9635,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}}},"source":["# print(len(*train_data_generate))"],"execution_count":11,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5c2bf20008da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_data_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tensorflow-2.0.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n\u001b[1;32m    131\u001b[0m             \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PIL_INTERPOLATION_METHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth_height_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1741\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"6xn7Ok2H9qTg","colab_type":"code","colab":{}},"source":["save_path = '/content/drive/Shared drives/scsa_2019_b/Project_Ai-KEA/code/model_checkpoint/'\n","date = 'day01'\n","epoch_n = 10\n","model_name = 'aikea_{}_{}_{}_{}.hdf5'.format(date, epoch_n, model_name, 0)\n","if not os.path.isdir(save_path):\n","    os.makedirs(save_path)\n","filepath = os.path.join(save_path, model_name)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FGkO3vsI5r-","colab_type":"text"},"source":["# Load Prev Model"]},{"cell_type":"code","metadata":{"id":"BgGFe84nInwx","colab_type":"code","colab":{}},"source":["# title format : aikea-{day01}-{sey}\n","def save_model(date, epoch, model_name, num):\n","    ai_kea.save(save_path+\"aikea_{}_{}_{}_{}.hdf5\".format(date, epoch, model_name, num))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdqD3HMJ8o9m","colab_type":"code","colab":{}},"source":["def load_model(date, epoch, model_name, num):\n","  model = load_model(save_path+\"aikea_{}_{}_{}_{}.hdf5\".format(date, epoch, model_name, num))\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sEeMnU8Ecog","colab_type":"code","colab":{}},"source":["# prev_ai_kea = load_models(\"mnist\",500)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KFKSnTxtPfnD","colab_type":"text"},"source":["#Load ResNet"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6zSfnjyVNbiq","colab":{}},"source":["def lr_schedule(epoch):\n","    lr = 1e-2\n","    if epoch/epoch_n > 0.7:\n","        lr *= 0.5e-3\n","    elif epoch/epoch_n > 0.6:\n","        lr *= 1e-3\n","    elif epoch/epoch_n > 0.3:\n","        lr *= 1e-2\n","    elif epoch/epoch_n > 0.1:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AP4DqLVoJPf9","colab_type":"code","colab":{}},"source":["# Prepare callbacks for model saving and for learning rate adjustment.\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc',\n","                             verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGDlEqVsJfjN","colab_type":"code","colab":{}},"source":["lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0,\n","                               patience=5, min_lr=0.5e-6)\n","\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cDIUQLSQwLj","colab_type":"code","colab":{}},"source":["def resnet_layer(inputs,num_filters=16,kernel_size=3,strides=1,\n","                 activation='relu',batch_normalization=True,conv_first=True):\n"," \n","    conv = Conv2D(num_filters, kernel_size=kernel_size,\n","                  strides=strides, padding='same',kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:          # conv first\n","        x = conv(x)\n","        if batch_normalization :\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:                   # activation first\n","        if batch_normalization :\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"36zXOZ7DI7ev","colab_type":"code","colab":{}},"source":["def resnet_v1(input_shape, depth, num_classes=10):\n","    if (depth - 2) % 6 != 0:\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n","    # Start model definition.\n","    num_filters = 16\n","    num_res_blocks = int((depth - 2) / 6)\n","\n","    inputs = Input(shape=input_shape)\n","    x = resnet_layer(inputs=inputs)           # first resnet\n","    # Instantiate the stack of residual units\n","    for stack in range(3):\n","        for res_block in range(num_res_blocks):\n","            strides = 1\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\n","                strides = 2  # downsample\n","            y = resnet_layer(inputs=x,num_filters=num_filters,strides=strides)\n","            y = resnet_layer(inputs=y,num_filters=num_filters,activation=None)\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\n","                # linear projection residual shortcut connection to match\n","                # changed dims\n","                x = resnet_layer(inputs=x,num_filters=num_filters,kernel_size=1,\n","                                 strides=strides,activation=None,batch_normalization=False)\n","            x = keras.layers.add([x, y])\n","            x = Activation('relu')(x)\n","        num_filters *= 2\n","\n","    # Add classifier on top.\n","    # v1 does not use BN after last shortcut connection-ReLU\n","    x = AveragePooling2D(pool_size=8)(x)\n","    y = Flatten()(x)\n","    outputs = Dense(num_classes,activation='softmax',\n","                    kernel_initializer='he_normal')(y)\n","\n","    # Instantiate model.\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbqX-7H2I-_1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"cc7288d3-5746-40ac-ef7b-a05a7e4164bf","executionInfo":{"status":"ok","timestamp":1576494125427,"user_tz":-540,"elapsed":1235,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}}},"source":["ai_kea = resnet_v1(input_shape=(img_size,img_size, 3), depth=depth)\n","\n","ai_kea.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(learning_rate=lr_schedule(0)),\n","              metrics=['accuracy'])\n","ai_kea.summary()\n","print(model_name)"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Learning rate:  0.01\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            [(None, 112, 112, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 112, 112, 16) 448         input_5[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 112, 112, 16) 64          conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 112, 112, 16) 0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 112, 112, 16) 2320        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 112, 112, 16) 64          conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 112, 112, 16) 0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 112, 112, 16) 2320        activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 112, 112, 16) 64          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 112, 112, 16) 0           activation_21[0][0]              \n","                                                                 batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 112, 112, 16) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 56, 56, 32)   4640        activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 56, 56, 32)   128         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 56, 56, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 56, 56, 32)   9248        activation_24[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 56, 56, 32)   544         activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 56, 56, 32)   128         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 56, 56, 32)   0           conv2d_33[0][0]                  \n","                                                                 batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 56, 56, 32)   0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 28, 28, 64)   18496       activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 28, 28, 64)   256         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 28, 28, 64)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 28, 28, 64)   36928       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 28, 28, 64)   2112        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 28, 28, 64)   256         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 28, 28, 64)   0           conv2d_36[0][0]                  \n","                                                                 batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 28, 28, 64)   0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 3, 3, 64)     0           activation_27[0][0]              \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 576)          0           average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 10)           5770        flatten_3[0][0]                  \n","==================================================================================================\n","Total params: 83,786\n","Trainable params: 83,306\n","Non-trainable params: 480\n","__________________________________________________________________________________________________\n","aikea_day01_10_aikea_day01_50_ResNet8v1_0.hdf5_0.hdf5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MjAnVJpiJQkE","colab_type":"text"},"source":["- Check Point"]},{"cell_type":"markdown","metadata":{"id":"XRoI3F4VSzRZ","colab_type":"text"},"source":["#model compile & train"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XmowB2CQNbik","colab":{}},"source":["from tensorflow.keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHHZxTEWRrd4","colab_type":"code","colab":{}},"source":["ai_kea.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v3Pnu0HXNbi0","outputId":"d936f094-15f2-4558-ec55-97d63119b36d","executionInfo":{"status":"error","timestamp":1576495620188,"user_tz":-540,"elapsed":1491045,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","batch_size = 80  # orig paper trained all networks with batch_size=128\n","epoch_n = 150  # 50\n","# Run training, with or without data augmentation.\n","data_augmentation = False\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    history = ai_kea.fit(train_data_generate, epochs=epoch_n,\n","                  validation_data=test_data_generate, shuffle=True,\n","                  callbacks=callbacks)\n","    # Score trained model.\n","    scores = model.evaluate(test_data_generate, verbose=1)\n","    print('Test loss:', scores[0])\n","    print('Test accuracy:', scores[1])"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Not using data augmentation.\n","Train for 19 steps, validate for 5 steps\n","Learning rate:  0.01\n","Epoch 1/150\n","18/19 [===========================>..] - ETA: 0s - loss: 2.6027 - accuracy: 0.2362WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 16s 816ms/step - loss: 2.5735 - accuracy: 0.2418 - val_loss: 133.7457 - val_accuracy: 0.1194\n","Learning rate:  0.01\n","Epoch 2/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.8402 - accuracy: 0.3852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 728ms/step - loss: 1.8253 - accuracy: 0.3906 - val_loss: 98.0170 - val_accuracy: 0.0706\n","Learning rate:  0.01\n","Epoch 3/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.5613 - accuracy: 0.5004WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 721ms/step - loss: 1.5605 - accuracy: 0.4993 - val_loss: 10.2427 - val_accuracy: 0.1107\n","Learning rate:  0.01\n","Epoch 4/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.4192 - accuracy: 0.5529WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 730ms/step - loss: 1.4090 - accuracy: 0.5552 - val_loss: 4.0422 - val_accuracy: 0.1933\n","Learning rate:  0.01\n","Epoch 5/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.3014 - accuracy: 0.5986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 1.2934 - accuracy: 0.6022 - val_loss: 2.6670 - val_accuracy: 0.3246\n","Learning rate:  0.01\n","Epoch 6/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.2089 - accuracy: 0.6311WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 1.2161 - accuracy: 0.6300 - val_loss: 6.3594 - val_accuracy: 0.1357\n","Learning rate:  0.01\n","Epoch 7/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.1121 - accuracy: 0.6505WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 727ms/step - loss: 1.1085 - accuracy: 0.6545 - val_loss: 2.5836 - val_accuracy: 0.3974\n","Learning rate:  0.01\n","Epoch 8/150\n","18/19 [===========================>..] - ETA: 0s - loss: 1.0459 - accuracy: 0.6805WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 1.0391 - accuracy: 0.6807 - val_loss: 4.3108 - val_accuracy: 0.2942\n","Learning rate:  0.01\n","Epoch 9/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.9585 - accuracy: 0.7101WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 0.9664 - accuracy: 0.7077 - val_loss: 1.8277 - val_accuracy: 0.4756\n","Learning rate:  0.01\n","Epoch 10/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.8689 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.8682 - accuracy: 0.7487 - val_loss: 3.0660 - val_accuracy: 0.3040\n","Learning rate:  0.01\n","Epoch 11/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.8160 - accuracy: 0.7618WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.8239 - accuracy: 0.7601 - val_loss: 2.0816 - val_accuracy: 0.4691\n","Learning rate:  0.01\n","Epoch 12/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.7943 - accuracy: 0.7660WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.7959 - accuracy: 0.7660 - val_loss: 6.1158 - val_accuracy: 0.1965\n","Learning rate:  0.01\n","Epoch 13/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.7489 - accuracy: 0.7820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 724ms/step - loss: 0.7539 - accuracy: 0.7806 - val_loss: 2.3950 - val_accuracy: 0.4148\n","Learning rate:  0.01\n","Epoch 14/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.7312 - accuracy: 0.7989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.7275 - accuracy: 0.8005 - val_loss: 3.3185 - val_accuracy: 0.3974\n","Learning rate:  0.01\n","Epoch 15/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.6548 - accuracy: 0.8271WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.6519 - accuracy: 0.8270 - val_loss: 1.6953 - val_accuracy: 0.5407\n","Learning rate:  0.01\n","Epoch 16/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.6237 - accuracy: 0.8282WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.6274 - accuracy: 0.8270 - val_loss: 1.7878 - val_accuracy: 0.5385\n","Learning rate:  0.001\n","Epoch 17/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.4889 - accuracy: 0.8899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.4868 - accuracy: 0.8910 - val_loss: 1.1902 - val_accuracy: 0.6580\n","Learning rate:  0.001\n","Epoch 18/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.4295 - accuracy: 0.9107WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.4337 - accuracy: 0.9085 - val_loss: 1.1804 - val_accuracy: 0.6536\n","Learning rate:  0.001\n","Epoch 19/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.4054 - accuracy: 0.9213WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 720ms/step - loss: 0.4094 - accuracy: 0.9201 - val_loss: 1.0993 - val_accuracy: 0.6884\n","Learning rate:  0.001\n","Epoch 20/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3924 - accuracy: 0.9284WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.3934 - accuracy: 0.9282 - val_loss: 1.0225 - val_accuracy: 0.6992\n","Learning rate:  0.001\n","Epoch 21/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3706 - accuracy: 0.9304WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.3742 - accuracy: 0.9293 - val_loss: 1.1547 - val_accuracy: 0.6862\n","Learning rate:  0.001\n","Epoch 22/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3625 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 722ms/step - loss: 0.3631 - accuracy: 0.9368 - val_loss: 1.0750 - val_accuracy: 0.6971\n","Learning rate:  0.001\n","Epoch 23/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3481 - accuracy: 0.9412WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 722ms/step - loss: 0.3514 - accuracy: 0.9395 - val_loss: 1.2435 - val_accuracy: 0.6623\n","Learning rate:  0.001\n","Epoch 24/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3326 - accuracy: 0.9478WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.3368 - accuracy: 0.9460 - val_loss: 1.1899 - val_accuracy: 0.6623\n","Learning rate:  0.001\n","Epoch 25/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3278 - accuracy: 0.9475WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.3265 - accuracy: 0.9490 - val_loss: 1.3264 - val_accuracy: 0.6460\n","Learning rate:  0.001\n","Epoch 26/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3129 - accuracy: 0.9563WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 0.3141 - accuracy: 0.9555 - val_loss: 1.1853 - val_accuracy: 0.6808\n","Learning rate:  0.001\n","Epoch 27/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.3004 - accuracy: 0.9583WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.3028 - accuracy: 0.9574 - val_loss: 1.2774 - val_accuracy: 0.6428\n","Learning rate:  0.001\n","Epoch 28/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2933 - accuracy: 0.9618WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.2935 - accuracy: 0.9611 - val_loss: 1.3926 - val_accuracy: 0.6221\n","Learning rate:  0.001\n","Epoch 29/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2863 - accuracy: 0.9626WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.2852 - accuracy: 0.9628 - val_loss: 1.2401 - val_accuracy: 0.6602\n","Learning rate:  0.001\n","Epoch 30/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2725 - accuracy: 0.9680WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.2739 - accuracy: 0.9679 - val_loss: 1.1617 - val_accuracy: 0.6862\n","Learning rate:  0.001\n","Epoch 31/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2581 - accuracy: 0.9706WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 720ms/step - loss: 0.2606 - accuracy: 0.9692 - val_loss: 1.1694 - val_accuracy: 0.6678\n","Learning rate:  0.001\n","Epoch 32/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2490 - accuracy: 0.9735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.2508 - accuracy: 0.9735 - val_loss: 1.1572 - val_accuracy: 0.6873\n","Learning rate:  0.001\n","Epoch 33/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2396 - accuracy: 0.9789WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.2434 - accuracy: 0.9773 - val_loss: 1.1420 - val_accuracy: 0.6895\n","Learning rate:  0.001\n","Epoch 34/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2333 - accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 712ms/step - loss: 0.2329 - accuracy: 0.9795 - val_loss: 1.0923 - val_accuracy: 0.7014\n","Learning rate:  0.001\n","Epoch 35/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2216 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.2247 - accuracy: 0.9825 - val_loss: 1.1616 - val_accuracy: 0.6775\n","Learning rate:  0.001\n","Epoch 36/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2150 - accuracy: 0.9846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.2166 - accuracy: 0.9838 - val_loss: 1.0765 - val_accuracy: 0.6960\n","Learning rate:  0.001\n","Epoch 37/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.2066 - accuracy: 0.9872WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 726ms/step - loss: 0.2061 - accuracy: 0.9873 - val_loss: 1.1660 - val_accuracy: 0.6938\n","Learning rate:  0.001\n","Epoch 38/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1995 - accuracy: 0.9912WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.2000 - accuracy: 0.9914 - val_loss: 1.1479 - val_accuracy: 0.6960\n","Learning rate:  0.001\n","Epoch 39/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.9903WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1936 - accuracy: 0.9908 - val_loss: 1.1337 - val_accuracy: 0.6949\n","Learning rate:  0.001\n","Epoch 40/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1860 - accuracy: 0.9943WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1858 - accuracy: 0.9943 - val_loss: 1.1100 - val_accuracy: 0.7068\n","Learning rate:  0.001\n","Epoch 41/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1776 - accuracy: 0.9937WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1780 - accuracy: 0.9941 - val_loss: 1.1136 - val_accuracy: 0.6982\n","Learning rate:  0.001\n","Epoch 42/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1695 - accuracy: 0.9966WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.1702 - accuracy: 0.9968 - val_loss: 1.0896 - val_accuracy: 0.7155\n","Learning rate:  0.001\n","Epoch 43/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1657 - accuracy: 0.9969WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.1658 - accuracy: 0.9968 - val_loss: 1.1308 - val_accuracy: 0.7144\n","Learning rate:  0.001\n","Epoch 44/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1589 - accuracy: 0.9980WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1588 - accuracy: 0.9978 - val_loss: 1.0881 - val_accuracy: 0.7134\n","Learning rate:  0.001\n","Epoch 45/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.9977WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 712ms/step - loss: 0.1541 - accuracy: 0.9978 - val_loss: 1.1751 - val_accuracy: 0.6982\n","Learning rate:  0.001\n","Epoch 46/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1480 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 722ms/step - loss: 0.1480 - accuracy: 0.9989 - val_loss: 1.1270 - val_accuracy: 0.7068\n","Learning rate:  0.0001\n","Epoch 47/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1408 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.1410 - accuracy: 0.9992 - val_loss: 1.0910 - val_accuracy: 0.7123\n","Learning rate:  0.0001\n","Epoch 48/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1385 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.1382 - accuracy: 0.9995 - val_loss: 1.0671 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 49/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1363 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1376 - accuracy: 0.9995 - val_loss: 1.0657 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 50/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1369 - accuracy: 0.9995 - val_loss: 1.0573 - val_accuracy: 0.7188\n","Learning rate:  0.0001\n","Epoch 51/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1365 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.1364 - accuracy: 0.9995 - val_loss: 1.0586 - val_accuracy: 0.7220\n","Learning rate:  0.0001\n","Epoch 52/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1364 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 712ms/step - loss: 0.1360 - accuracy: 0.9995 - val_loss: 1.0606 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 53/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1354 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 712ms/step - loss: 0.1355 - accuracy: 0.9995 - val_loss: 1.0599 - val_accuracy: 0.7242\n","Learning rate:  0.0001\n","Epoch 54/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1354 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1350 - accuracy: 0.9995 - val_loss: 1.0651 - val_accuracy: 0.7296\n","Learning rate:  0.0001\n","Epoch 55/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1344 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1346 - accuracy: 0.9995 - val_loss: 1.0653 - val_accuracy: 0.7242\n","Learning rate:  0.0001\n","Epoch 56/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1344 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.1342 - accuracy: 0.9995 - val_loss: 1.0667 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 57/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1334 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1336 - accuracy: 0.9995 - val_loss: 1.0697 - val_accuracy: 0.7231\n","Learning rate:  0.0001\n","Epoch 58/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1331 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.1332 - accuracy: 0.9995 - val_loss: 1.0733 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 59/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1327 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1330 - accuracy: 0.9995 - val_loss: 1.0748 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 60/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1323 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 720ms/step - loss: 0.1324 - accuracy: 0.9995 - val_loss: 1.0739 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 61/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1318 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 722ms/step - loss: 0.1321 - accuracy: 0.9995 - val_loss: 1.0779 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 62/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1314 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 0.1316 - accuracy: 0.9997 - val_loss: 1.0792 - val_accuracy: 0.7220\n","Learning rate:  0.0001\n","Epoch 63/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1309 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.1311 - accuracy: 0.9995 - val_loss: 1.0832 - val_accuracy: 0.7231\n","Learning rate:  0.0001\n","Epoch 64/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1309 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 0.1308 - accuracy: 0.9997 - val_loss: 1.0840 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 65/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1303 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.1303 - accuracy: 0.9997 - val_loss: 1.0857 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 66/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1289 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 723ms/step - loss: 0.1299 - accuracy: 0.9997 - val_loss: 1.0862 - val_accuracy: 0.7166\n","Learning rate:  0.0001\n","Epoch 67/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1293 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 712ms/step - loss: 0.1295 - accuracy: 0.9997 - val_loss: 1.0877 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 68/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1290 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 724ms/step - loss: 0.1290 - accuracy: 0.9997 - val_loss: 1.0879 - val_accuracy: 0.7199\n","Learning rate:  0.0001\n","Epoch 69/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1286 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1286 - accuracy: 0.9997 - val_loss: 1.0915 - val_accuracy: 0.7188\n","Learning rate:  0.0001\n","Epoch 70/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1281 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1283 - accuracy: 0.9997 - val_loss: 1.0919 - val_accuracy: 0.7199\n","Learning rate:  0.0001\n","Epoch 71/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1282 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.1279 - accuracy: 0.9997 - val_loss: 1.0910 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 72/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1271 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.1274 - accuracy: 0.9997 - val_loss: 1.0933 - val_accuracy: 0.7210\n","Learning rate:  0.0001\n","Epoch 73/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1266 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1268 - accuracy: 0.9997 - val_loss: 1.0938 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 74/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1264 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1266 - accuracy: 0.9997 - val_loss: 1.0931 - val_accuracy: 0.7144\n","Learning rate:  0.0001\n","Epoch 75/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1262 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 13s 710ms/step - loss: 0.1261 - accuracy: 1.0000 - val_loss: 1.0978 - val_accuracy: 0.7188\n","Learning rate:  0.0001\n","Epoch 76/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1256 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 13s 710ms/step - loss: 0.1257 - accuracy: 0.9997 - val_loss: 1.0963 - val_accuracy: 0.7134\n","Learning rate:  0.0001\n","Epoch 77/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1247 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1253 - accuracy: 0.9997 - val_loss: 1.1010 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 78/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1248 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.7155\n","Learning rate:  0.0001\n","Epoch 79/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1244 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.7220\n","Learning rate:  0.0001\n","Epoch 80/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1252 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 1.0998 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 81/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1234 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.7155\n","Learning rate:  0.0001\n","Epoch 82/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1242 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1231 - accuracy: 1.0000 - val_loss: 1.1035 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 83/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1229 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1228 - accuracy: 1.0000 - val_loss: 1.1029 - val_accuracy: 0.7166\n","Learning rate:  0.0001\n","Epoch 84/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1223 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 720ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.7166\n","Learning rate:  0.0001\n","Epoch 85/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1218 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 1.1066 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 86/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1215 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1215 - accuracy: 1.0000 - val_loss: 1.1106 - val_accuracy: 0.7199\n","Learning rate:  0.0001\n","Epoch 87/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1210 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.7155\n","Learning rate:  0.0001\n","Epoch 88/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1208 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1208 - accuracy: 1.0000 - val_loss: 1.1125 - val_accuracy: 0.7155\n","Learning rate:  0.0001\n","Epoch 89/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1214 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 1.1080 - val_accuracy: 0.7155\n","Learning rate:  0.0001\n","Epoch 90/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1196 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 721ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 1.1140 - val_accuracy: 0.7177\n","Learning rate:  0.0001\n","Epoch 91/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1196 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 722ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.7166\n","Learning rate:  1e-05\n","Epoch 92/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1188 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 1.1127 - val_accuracy: 0.7155\n","Learning rate:  1e-05\n","Epoch 93/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 94/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1189 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 714ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 95/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 96/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 1.1179 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 97/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 1.1187 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 98/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 711ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 1.1192 - val_accuracy: 0.7123\n","Learning rate:  1e-05\n","Epoch 99/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1184 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.7144\n","Learning rate:  1e-05\n","Epoch 100/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1184 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 712ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.7144\n","Learning rate:  1e-05\n","Epoch 101/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 718ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 1.1208 - val_accuracy: 0.7144\n","Learning rate:  1e-05\n","Epoch 102/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 1.1213 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 103/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 719ms/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 1.1214 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 104/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 1.1215 - val_accuracy: 0.7123\n","Learning rate:  1e-05\n","Epoch 105/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1184 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 713ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.7134\n","Learning rate:  1e-05\n","Epoch 106/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 715ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 1.1224 - val_accuracy: 0.7134\n","Learning rate:  5e-06\n","Epoch 107/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 716ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.7134\n","Learning rate:  5e-06\n","Epoch 108/150\n","18/19 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","19/19 [==============================] - 14s 717ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.7134\n","Learning rate:  5e-06\n","Epoch 109/150\n"," 1/19 [>.............................] - ETA: 2:18WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr\n"," 1/19 [>.............................] - ETA: 2:20"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-83-7ee4fbfbeeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch_size = 80  # orig paper trained all networks with batch_size=128\\nepoch_n = 150  # 50\\n# Run training, with or without data augmentation.\\ndata_augmentation = False\\n\\nif not data_augmentation:\\n    print('Not using data augmentation.')\\n    history = ai_kea.fit(train_data_generate, epochs=epoch_n,\\n                  validation_data=test_data_generate, shuffle=True,\\n                  callbacks=callbacks)\\n    # Score trained model.\\n    scores = model.evaluate(test_data_generate, verbose=1)\\n    print('Test loss:', scores[0])\\n    print('Test accuracy:', scores[1])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"2jA7GwORImmi","colab_type":"text"},"source":["# Save Model"]},{"cell_type":"code","metadata":{"id":"yFA6DDa3MhyW","colab_type":"code","outputId":"ea87b42c-168a-43af-a4f1-2ba40d0429e6","executionInfo":{"status":"ok","timestamp":1576495621252,"user_tz":-540,"elapsed":1050,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["%%time\n","\n","# date, epoch, model_name, num\n","save_model(date, epoch=epoch_n, model_name=model_name, num='sey02')"],"execution_count":84,"outputs":[{"output_type":"stream","text":["CPU times: user 94.5 ms, sys: 9.88 ms, total: 104 ms\n","Wall time: 130 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OsFmvxBmIINJ","colab_type":"text"},"source":["# Plot Learning Status"]},{"cell_type":"code","metadata":{"id":"MmwAohA9TYCc","colab_type":"code","outputId":"43ef4039-126b-4473-b274-1c46b8e1c87e","executionInfo":{"status":"ok","timestamp":1576495625394,"user_tz":-540,"elapsed":1691,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":607}},"source":["import matplotlib.pyplot as plt\n","\n","losses = history.history['loss']\n","val_loss = history.history['val_loss']\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.figure(figsize=(10, 10))\n","plt.subplot(2, 1, 1)\n","plt.semilogy(losses, label='lossi')\n","plt.semilogy(val_loss, label='val_loss_')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.title(\"LOSS\")\n","\n","plt.subplot(2, 1, 2)\n","plt.ylim(0.5,1)\n","plt.semilogy(acc, label='accuracy')\n","plt.semilogy(val_acc, label='val_accuracy')\n","plt.grid(True)\n","plt.legend(loc='best')\n","plt.title(\"Accuraty\")\n","plt.show()  "],"execution_count":85,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAmwAAAJOCAYAAAAK8VsYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j+D1sAd9fnF4wAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 720x720 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"n_958RQ3IOON","colab_type":"code","outputId":"2d2a8e52-2ea3-42ed-fbdc-14768b79ae84","executionInfo":{"status":"ok","timestamp":1576495629417,"user_tz":-540,"elapsed":1043,"user":{"displayName":"Libby Yu","photoUrl":"","userId":"01761481636192670645"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(np.max(history.history['val_accuracy']))"],"execution_count":86,"outputs":[{"output_type":"stream","text":["0.74592835\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HSGQWFlMD5nM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}